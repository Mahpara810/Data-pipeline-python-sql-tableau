# Data-pipeline-python-sql-tableau
End-to-end data analytics project using Python, SQL Server, and Tableau for ETL, storage, and visualization.
# End-to-End Data Analytics Project using Python, SQL Server & Tableau
This project demonstrates an end-to-end data analytics workflow â€” from data extraction and transformation using Python, to storage and querying with SQL Server, and finally data visualization using Tableau. It aims to generate meaningful business insights through automation and reporting.
# ğŸ“ Project Structure

```text
Data-pipeline-python-sql-tableau/
â”‚
â”œâ”€â”€ data/               # Raw or sample datasets
â”œâ”€â”€ python/             # Python scripts for ETL
â”œâ”€â”€ sql/                # SQL scripts (DDL/DML queries)
â”œâ”€â”€ tableau/            # Tableau workbooks (.twb/.twbx files or screenshots)
â”œâ”€â”€ README.md           # Project documentation
â””â”€â”€ requirements.txt    # Python dependencies
```



# ğŸ’» Technologies Used
â€¢ Python (Pandas, SQLAlchemy/pyodbc) â€“ for data extraction, transformation (ETL)

â€¢ SQL Server â€“ for data storage and querying

â€¢ Tableau â€“ for building interactive dashboards

â€¢ Jupyter Notebook â€“ for EDA and testing
# âœ¨ Features
â€¢ Automated ETL using Python

â€¢ Cleaned and normalized data stored in SQL Server

â€¢ Interactive dashboards in Tableau

â€¢ Real-world dataset (customizable)

â€¢ Modular codebase and reusable scripts

# ğŸš€  How to Run

## 1. Clone the Repository

```bash
git clone https://github.com/Mahpara810/Data-pipeline-python-sql-tableau
cd Data-pipeline-python-sql-tableau
```
## 2. Set Up the Environment
```bash
pip install -r requirements.txt
```
## 3. Data Source

The dataset used in this project is publicly available on Kaggle:  

[Telco Customer Churn Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
## 4 Run the ETL and Data Modeling Notebook

â€¢ Open the Jupyter Notebook:  
  `notebooks/Telecom-customer-churn.ipynb`

â€¢ This notebook performs:
  - Data loading and cleaning  
  - Transformation into a star schema (fact and dimension tables)  
  - Uploading the transformed data into the existing tables in the SQL Server database.

â€¢ Ensure your SQL Server connection details (host, database, username, password) are correctly configured in the notebook.

â€¢ After connecting, verify that data of the fact and dimension tables have been successfully loaded into SQL Server.
## 5. Set Up SQL Server
â€¢  Create a new database.

â€¢ Run the SQL scripts in the sql/ folder to create the required tables.

â€¢ Make a connection to SQL Server from the Jupyter notebook using pyodbc or sqlalchemy.

â€¢ Push the cleaned and transformed data from the notebook into the SQL Server tables using pandas.to_sql() or SQL queries.

## 6. Open Tableau Dashboard
â€¢ Open the .twb or .twbx file from the tableau/ folder using Tableau.

â€¢ Connect to your SQL Server database, or use the extracted data embedded in the workbook.

## 7. Explore the Dashboards!
â€¢ Explore and analyze the visualized data insights to uncover trends, patterns, and key metrics.



# ğŸ“Š Dashboard
![Capture](https://github.com/user-attachments/assets/792d2dfd-cabe-44b3-920a-2f194f1165a7)




# âœ… Use Cases
This template can be adapted for:

â€¢ Sales Performance Analysis

â€¢ Customer Segmentation

â€¢ Financial Reporting

â€¢ Healthcare Data Analysis

â€¢ Marketing Campaign Insights
 #  ğŸ“š Resources and References
## 1. Dataset Source:
[Telco Customer Churn Dataset](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)
This dataset, provided by IBM Sample Data Sets, includes information about a telecom company's customers, such as services signed up for, customer account information, and whether or not the customer churned. It's commonly used for customer retention and churn prediction modeling.

## 2. Official Library Documentation:

â€¢ Pandas Documentation

â€¢ NumPy Documentation

â€¢ Matplotlib Documentation

â€¢ Seaborn Documentation

â€¢ Scikit-learn Documentation

## ğŸ“˜ Additional Learning Resources (if applicable):

â€¢ IBM Developer â€“ Predict customer churn with SciKit-Learn

â€¢ Medium Article â€“ Customer Churn Prediction with Telco Dataset
# ğŸŒŸ Acknowledgments
â€¢ Thanks to IBM Sample Data Sets for providing the Telco Customer Churn dataset.

â€¢ Special thanks to Kaggle for hosting and making the dataset easily accessible to the data science community.

â€¢ Gratitude to the open-source community behind tools like Pandas, NumPy, Matplotlib and Seaborn.

â€¢ Appreciation to the authors of various tutorials and blog posts that helped guide the data exploration and model building process.
# ğŸ¤Contributions
Contributions are welcome! Please fork the repo, make your changes, and submit a pull request.

# ğŸ“ License
This project is licensed under the [MIT License](LICENSE).









